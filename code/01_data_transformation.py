# -*- coding: utf-8 -*-
"""01_Data_Transformation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18ZNWkxEfOvz6ULv0mT072FwjcTo4UYTF

"""

import os
import math
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from statsmodels.tsa.stattools import adfuller, kpss
from statsmodels.tsa.stattools import pacf as sm_pacf

# Configure plotting style
plt.style.use('seaborn-v0_8-whitegrid')


# Define dataset path
DAILY_SALES_PATH = "../dataset/dataset_daily_sales.csv"

"""## 2. Utility Functions
Helper functions for normalization, statistical calculations, and transformations.
"""

def solve_linear_system(A, b):
    A = [row[:] for row in A]
    b = list(b)
    n = len(A)

    for i in range(n):
        pivot = A[i][i]
        if pivot == 0:
            raise ValueError("Zero pivot encountered")

        for j in range(i, n):
            A[i][j] /= pivot
        b[i] /= pivot

        for k in range(i + 1, n):
            factor = A[k][i]
            for j in range(i, n):
                A[k][j] -= factor * A[i][j]
            b[k] -= factor * b[i]

    x = [0.0] * n
    for i in range(n - 1, -1, -1):
        s = sum(A[i][j] * x[j] for j in range(i + 1, n))
        x[i] = b[i] - s
    return x

def normalize_series(series):
    """Standardizes a pandas Series (Z-score normalization)."""
    mean_val = series.mean()
    std_dev = series.std()
    return (series - mean_val) / std_dev

def calculate_acf(series, n_lags):
    """Calculates the Autocorrelation Function (ACF) manually."""
    acf_values = []
    for lag in range(n_lags + 1):
        if lag == 0:
            acf_values.append(1.0)
        else:
            # Compute correlation with shifted series
            correlation = series.corr(series.shift(lag))
            acf_values.append(correlation)
    return pd.Series(acf_values, index=range(n_lags + 1))

def variance_stabilizing_log(series):
    """Applies log transformation, shifting data if necessary to handle non-positive values."""
    s = series.copy().astype(float)
    min_val = s.min()

    # Shift series to ensure all values are positive before log
    if min_val <= 0:
        shift = 1.0 - min_val
        s = s + shift

    return s.apply(lambda x: math.log(x))

def calculate_pacf_safe(series, nlags):
    s = series.dropna().astype(float)
    nlags = min(nlags, len(s) - 1)
    return sm_pacf(s, nlags=nlags, method="ywm")

"""## 3. Data Loading and Cleaning
Load the dataset and filter for relevant sales transactions.
"""

# Load dataset with low_memory=False to handle mixed types warning
daily_sales_df = pd.read_csv(DAILY_SALES_PATH, low_memory=False)

# Filter for 'Sales Units' and remove zero-amount records
daily_sales_df = daily_sales_df[
    (daily_sales_df['Account'] == 'Sales Units') &
    (daily_sales_df['Amount'] != 0)
]

"""## 4. Monthly Aggregation for SARIMA by Customer Steering L3
Aggregate daily sales to a monthly panel with separate net sales and returns.


"""

monthly_base_df = daily_sales_df[
    ["CUST_STEERING_L3_NAME", "ACCOUNTING_PERIOD", "Amount"]
].copy()

monthly_base_df = monthly_base_df.dropna(
    subset=["CUST_STEERING_L3_NAME", "ACCOUNTING_PERIOD"]
)

monthly_base_df["ACCOUNTING_PERIOD"] = (
    monthly_base_df["ACCOUNTING_PERIOD"].astype(str).str.strip()
)

monthly_base_df["Amount"] = pd.to_numeric(
    monthly_base_df["Amount"], errors="coerce"
)
monthly_base_df = monthly_base_df.dropna(subset=["Amount"])

# Split into net sales (Amount > 0) and returns (Amount < 0)
sales_df = monthly_base_df[monthly_base_df["Amount"] > 0].copy()
returns_df = monthly_base_df[monthly_base_df["Amount"] < 0].copy()

# Monthly aggregation for net sales
monthly_sales_df = (
    sales_df
    .groupby(["CUST_STEERING_L3_NAME", "ACCOUNTING_PERIOD"], as_index=False)["Amount"]
    .sum()
    .rename(columns={"Amount": "net_sales_units"})
)

# Monthly aggregation for returns (as positive units)
monthly_returns_df = (
    returns_df
    .groupby(["CUST_STEERING_L3_NAME", "ACCOUNTING_PERIOD"], as_index=False)["Amount"]
    .sum()
)
monthly_returns_df["returns_units"] = monthly_returns_df["Amount"].abs()
monthly_returns_df = monthly_returns_df.drop(columns=["Amount"])

# Merge net sales and returns into a single monthly panel
monthly_panel = pd.merge(
    monthly_sales_df,
    monthly_returns_df,
    on=["CUST_STEERING_L3_NAME", "ACCOUNTING_PERIOD"],
    how="outer"
)

# Fill missing values and compute total net units
monthly_panel["net_sales_units"] = monthly_panel["net_sales_units"].fillna(0.0)
monthly_panel["returns_units"] = monthly_panel["returns_units"].fillna(0.0)
monthly_panel["total_net_units"] = (
    monthly_panel["net_sales_units"] - monthly_panel["returns_units"]
)

# Build Period index from ACCOUNTING_PERIOD (YYYYMM)
year_vals = monthly_panel["ACCOUNTING_PERIOD"].str.slice(0, 4).astype(int)
month_vals = monthly_panel["ACCOUNTING_PERIOD"].str.slice(4, 6).astype(int)
monthly_panel["period"] = pd.PeriodIndex(
    year=year_vals, month=month_vals, freq="M"
)

# Ensure a complete monthly range per CUST_STEERING_L3_NAME (no missing months)
cust_bounds = (
    monthly_panel
    .groupby("CUST_STEERING_L3_NAME")["period"]
    .agg(["min", "max"])
    .reset_index()
)

completed_panel_list = []

for _, row in cust_bounds.iterrows():
    cust_name = row["CUST_STEERING_L3_NAME"]
    period_start = row["min"]
    period_end = row["max"]

    period_range = pd.period_range(start=period_start, end=period_end, freq="M")
    temp = pd.DataFrame({"period": period_range})

    cust_data = monthly_panel[
        monthly_panel["CUST_STEERING_L3_NAME"] == cust_name
    ][["period", "net_sales_units", "returns_units", "total_net_units"]]

    temp = temp.merge(cust_data, on="period", how="left")

    temp["CUST_STEERING_L3_NAME"] = cust_name

    value_cols = ["net_sales_units", "returns_units", "total_net_units"]
    temp[value_cols] = temp[value_cols].fillna(0.0)

    completed_panel_list.append(temp)

completed_panel = pd.concat(completed_panel_list, ignore_index=True)

# Rebuild ACCOUNTING_PERIOD as YYYYMM from the Period index
completed_panel["period_start"] = completed_panel["period"].dt.to_timestamp()
completed_panel["ACCOUNTING_PERIOD"] = (
    completed_panel["period_start"].dt.strftime("%Y%m")
)

# Final selection and ordering of columns
completed_panel = completed_panel[
    [
        "CUST_STEERING_L3_NAME",
        "ACCOUNTING_PERIOD",
        "net_sales_units",
        "returns_units",
        "total_net_units",
    ]
].sort_values(["CUST_STEERING_L3_NAME", "ACCOUNTING_PERIOD"])

# Save monthly dataset next to the daily sales dataset
base_dir = os.path.dirname(DAILY_SALES_PATH)
monthly_output_path = os.path.join(
    base_dir, "dataset_monthly_cust_l3_sarima.csv"
)

completed_panel.to_csv(monthly_output_path, index=False)